{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the libraries \n",
    "%matplotlib inline\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "import glob\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Sequential\n",
    "from keras.metrics import *\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from scipy.stats import norm\n",
    "from keras.preprocessing import image\n",
    "from keras import datasets\n",
    "\n",
    "from keras import backend as K\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure\n",
    "plt.gray()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #model will be trained on GPU 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    x_size = 64\n",
    "    y_size = 64\n",
    "    image_list = np.zeros((len(path), x_size, y_size,1))\n",
    "    target_list = np.zeros((len(path), x_size, y_size,1))\n",
    "\n",
    "    for i, fig in enumerate(path):\n",
    "        img = image.load_img(fig, grayscale=True)#, target_size=(x_size, y_size))\n",
    "        img = image.img_to_array(img).astype('float32')\n",
    "        img = img / 255.0\n",
    "        '''\n",
    "        max_i = img.max()\n",
    "        min_i = img.min()\n",
    "        \n",
    "        #print(img.shape)\n",
    "        if max_i == min_i:\n",
    "            img = np.zeros((64,64,1))\n",
    "        else:\n",
    "            img = (img - min_i) / (max_i - min_i)\n",
    "            img = exposure.equalize_adapthist(img[:, :, 0])\n",
    "        #print(img.shape)\n",
    "        '''\n",
    "        try:\n",
    "            image_list[i] = img.reshape(64,64,1)#exposure.equalize_adapthist(img[:,:,0])\n",
    "            \n",
    "            target = cv2.imread(fig.split('.')[0] + '_target.png')[:, :, :1]\n",
    "            target_list[i] = target\n",
    "        except:\n",
    "            print(fig)\n",
    "            pass\n",
    "        \n",
    "    return image_list, target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_img = glob.glob(\"/home/webvalley/Documents/plaque-image-preprocessing/Data/Patches/Plaque/Aug/cal/*.png\")\n",
    "train_img += glob.glob(\"/home/webvalley/Documents/plaque-image-preprocessing/Data/Patches/Plaque/Aug/fibrous/*.png\")\n",
    "train_img += random.sample(glob.glob(\"/home/webvalley/Documents/plaque-image-preprocessing/Data/Patches/NoPlaque/*.png\"), 3790)\n",
    "\"\"\"\n",
    "all_img = [i for i in glob.glob(\"test4/*.png\") if 'target' not in i]\n",
    "\n",
    "\n",
    "all_noplaques = [i for i in all_img if 'noplaque' in i]\n",
    "all_plaques = [i for i in all_img if 'noplaque' not in i]\n",
    "\n",
    "\n",
    "all_noplaques_ids = list(set([os.path.basename(i).split('_')[1] for i in all_noplaques]))\n",
    "_, all_noplaques_ids_test = train_test_split(all_noplaques_ids, test_size=30, random_state=42)\n",
    "\n",
    "all_noplaques_ids_test = set(all_noplaques_ids_test)\n",
    "all_noplaques = [i for i in all_noplaques if os.path.basename(i).split('_')[1] in all_noplaques_ids_test]\n",
    "print(len(all_noplaques))\n",
    "print(len(all_plaques))\n",
    "\n",
    "\n",
    "all_img = all_noplaques + all_plaques\n",
    "print(len(all_img))\n",
    "ids = list(set([os.path.basename(i).split('_')[1] for i in all_img]))\n",
    "\n",
    "ids_train, ids_test = train_test_split(ids, test_size=0.2, random_state=42)\n",
    "\n",
    "ids_train = set(ids_train)\n",
    "ids_test = set(ids_test)\n",
    "\n",
    "train_img = [i for i in all_img if os.path.basename(i).split('_')[1] in ids_train]\n",
    "test_img = [i for i in all_img if os.path.basename(i).split('_')[1] in ids_test]\n",
    "\n",
    "random.shuffle(train_img)\n",
    "random.shuffle(test_img)\n",
    "\n",
    "x_train, y_train = load_image(train_img)\n",
    "x_test, y_test = load_image(test_img) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_train[10]\n",
    "target = y_test[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_train), len(y_train), len(x_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_plaques), len(all_noplaques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(train_img).intersection(set(test_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.shape)\n",
    "plt.imshow(img[:,:,0])\n",
    "plt.figure()\n",
    "plt.imshow(target[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape, x_train.shape\n",
    "\n",
    "plt.imshow(x_train[0, :, :, 0])\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(x_test[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_test), np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 200\n",
    "inChannel = 1\n",
    "x, y = 64, 64\n",
    "input_img = Input(shape = (x, y, inChannel))\n",
    "print(input_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols, img_chns = x, y, 1\n",
    "# number of convolutional filters to use\n",
    "NB_FILTERS = 16\n",
    "# convolution kernel size\n",
    "KERNEL_SIZE = (3, 3)\n",
    "\n",
    "\n",
    "LATENT_DIM = 128\n",
    "INTERMEDIATE_DIM = 256\n",
    "NB_EPOCHS = 100\n",
    "\n",
    "conv_1 = Conv2D(1, kernel_size=(2, 2), padding='same', activation='relu')(input_img)\n",
    "conv_2 = Conv2D(NB_FILTERS, kernel_size=(2, 2),\n",
    "                       padding='same', activation='relu',\n",
    "                       strides=(2, 2))(conv_1)\n",
    "conv_3 = Conv2D(NB_FILTERS, KERNEL_SIZE,\n",
    "                       padding='same', activation='relu',\n",
    "                       strides=(1, 1))(conv_2)\n",
    "conv_4 = Conv2D(NB_FILTERS, KERNEL_SIZE,\n",
    "                       padding='same', activation='relu',\n",
    "                       strides=(1, 1))(conv_3)\n",
    "flat = Reshape((-1,))(conv_4)\n",
    "\n",
    "dropout1 = Dropout(rate=0.4)(flat)\n",
    "hidden = Dense(INTERMEDIATE_DIM, activation='relu')(dropout1)\n",
    "dropout2 = Dropout(rate=0.4)(hidden)\n",
    "\n",
    "z = Dense(LATENT_DIM)(dropout2)\n",
    "\n",
    "decoder_hid = Dense(INTERMEDIATE_DIM, activation='relu')(z)\n",
    "\n",
    "dropout3 = Dropout(rate=0.4)(decoder_hid)\n",
    "decoder_upsample = Dense(NB_FILTERS * img_rows//2 * img_rows//2, activation='relu')(dropout3)\n",
    "dropout4 = Dropout(rate=0.4)(decoder_upsample)\n",
    "\n",
    "decoder_reshape = Reshape((img_rows//2, img_rows//2, NB_FILTERS))(dropout4)\n",
    "decoder_deconv_1 = Conv2DTranspose(NB_FILTERS, KERNEL_SIZE,\n",
    "                                   padding='same',\n",
    "                                   strides=(1, 1),\n",
    "                                   activation='relu')(decoder_reshape)\n",
    "decoder_deconv_2 = Conv2DTranspose(NB_FILTERS, KERNEL_SIZE,\n",
    "                                   padding='same',\n",
    "                                   strides=(1, 1),\n",
    "                                   activation='relu')(decoder_deconv_1)\n",
    "\n",
    "decoder_deconv_3_upsamp = Conv2DTranspose(NB_FILTERS, kernel_size=(2, 2),\n",
    "                                          padding='valid',\n",
    "                                          strides=(2, 2),\n",
    "                                          activation='relu')(decoder_deconv_2)\n",
    "decoder_mean_squash = Conv2D(img_chns, kernel_size=(1, 1),\n",
    "                                    padding='valid',\n",
    "                                    activation='sigmoid')(decoder_deconv_3_upsamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "\n",
    "model = Model(input_img, decoder_mean_squash)\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='mse')#dice_coef_loss, metrics=[dice_coef])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=5, mode='auto')\n",
    "history = model.fit(\n",
    "    x_train, \n",
    "    y_train, \n",
    "    epochs=epochs, \n",
    "    batch_size=batch_size, \n",
    "    validation_data=(x_test, y_test)\n",
    ")#, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('Training Loss Plot')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.title('Val Loss Plot')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('autoencoder.h5') \n",
    "model.save_weights('autoencoder_w.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "\n",
    "# adam = optimizers.Adam(lr=0.01)\n",
    "\n",
    "encoder = Model(input_img, z)\n",
    "#encoder.compile(optimizer=Adam(lr=0.0001), loss='mse')#dice_coef, metrics=[dice_coef_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs_test = encoder.predict(x_test)\n",
    "decoded_imgs_test = model.predict(x_test)\n",
    "\n",
    "encoded_imgs_train = encoder.predict(x_train)\n",
    "decoded_imgs_train = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs2 = encoder.predict(x2_test)\n",
    "decoded_imgs2 = model.predict(x2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs.shape\n",
    "#print(encoded_imgs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_conv = {\n",
    "    0: 'NoPlaque',\n",
    "    1: 'Calcific',\n",
    "    2: 'Fibrous'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct = [np.unique(y_train[i]) for i in range(y_train.shape[0])]\n",
    "print([i for i in distinct if 1 in i and 2 in i])\n",
    "\n",
    "distinct = [np.unique(y_test[i]) for i in range(y_test.shape[0])]\n",
    "[i for i in distinct if 1 in i and 2 in i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_set = x_train\n",
    "y_set = y_train\n",
    "encoded_imgs_set = encoded_imgs_train\n",
    "decoded_imgs_set = decoded_imgs_train\n",
    "\n",
    "for i in range(11):\n",
    "    fig, ((ax1, ax2, ax3, ax4)) = plt.subplots(1, 4)\n",
    "    \n",
    "    label = y_set[i].max()\n",
    "    fig.suptitle(f\"[{i}] Label: \" + label_conv[label], fontsize=16)\n",
    "    \n",
    "    ax1.imshow(x_set[i, :, :, 0])\n",
    "    ax1.set_title(\"Original\")\n",
    "    \n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax2.imshow(encoded_imgs_set[i].reshape((16, 8)))\n",
    "    ax2.set_title(\"Encoded\")\n",
    "    \n",
    "    ax2.get_xaxis().set_visible(False)\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax3.imshow(decoded_imgs_set[i].reshape((64, 64)))\n",
    "    ax3.set_title(\"Decoded\")\n",
    "    \n",
    "    ax3.get_xaxis().set_visible(False)\n",
    "    ax3.get_yaxis().set_visible(False)\n",
    "    \n",
    "    \n",
    "    ax4.imshow(y_set[i].reshape((64, 64)))\n",
    "    ax4.set_title(\"Target\")\n",
    "    \n",
    "    ax4.get_xaxis().set_visible(False)\n",
    "    ax4.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_set = x_train\n",
    "y_set = y_train\n",
    "encoded_imgs_set = encoded_imgs_train\n",
    "decoded_imgs_set = decoded_imgs_train\n",
    "i = train_img.index('test4/conv_D3TBFJS0_1.png')\n",
    "fig, ((ax1, ax2, ax3, ax4)) = plt.subplots(1, 4)\n",
    "\n",
    "label = y_set[i].max()\n",
    "fig.suptitle(f\"[{i}] Label: \" + label_conv[label], fontsize=16)\n",
    "\n",
    "\n",
    "ax1.imshow(x_set[i, :, :, 0])\n",
    "ax1.set_title(\"Original\")\n",
    "\n",
    "ax1.get_xaxis().set_visible(False)\n",
    "ax1.get_yaxis().set_visible(False)\n",
    "\n",
    "ax2.imshow(encoded_imgs_set[i].reshape((16, 8)))\n",
    "ax2.set_title(\"Encoded\")\n",
    "    \n",
    "ax2.get_xaxis().set_visible(False)\n",
    "ax2.get_yaxis().set_visible(False)\n",
    "\n",
    "ax3.imshow(decoded_imgs_set[i].reshape((64, 64)))\n",
    "ax3.set_title(\"Decoded\")\n",
    "\n",
    "ax3.get_xaxis().set_visible(False)\n",
    "ax3.get_yaxis().set_visible(False)\n",
    "\n",
    "\n",
    "ax4.imshow(y_set[i].reshape((64, 64)))\n",
    "ax4.set_title(\"Target\")\n",
    "\n",
    "ax4.get_xaxis().set_visible(False)\n",
    "ax4.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = glob.glob('sagittal_conv_D538Q626*')\n",
    "\n",
    "\n",
    "x3_test = load_image(p)\n",
    "\n",
    "print(x3_test.shape)\n",
    "y3_test = []\n",
    "\n",
    "\n",
    "for img in p:\n",
    "   \n",
    "    if \"Calcific\" in img:\n",
    "        y3_test.append(0)\n",
    "    elif \"Fibrous\" in img:\n",
    "        y3_test.append(1)\n",
    "    elif \"noplaque\" in img:\n",
    "        y3_test.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs3 = encoder.predict(x3_test)\n",
    "decoded_imgs3 = model.predict(x3_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cos_sim = cosine_similarity(encoded_imgs[2].reshape(1,-1), encoded_imgs[1].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.subtract(encoded_imgs[0], encoded_imgs[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_imgs[np.array(y_test) == 1]\n",
    "plt.title(\"SCATTER\")\n",
    "plt.scatter(encoded_imgs[np.array(y_test) == 0][:, 0], encoded_imgs[np.array(y_test) == 0][:, 1], label='Calcific', alpha=0.5)\n",
    "plt.scatter(encoded_imgs[np.array(y_test) == 1][:, 0], encoded_imgs[np.array(y_test) == 1][:, 1], label='Fibrous', alpha=0.5)\n",
    "plt.scatter(encoded_imgs[np.array(y_test) == 2][:, 0], encoded_imgs[np.array(y_test) == 2][:, 1], label='No Plaque', alpha=0.5)\n",
    "plt.scatter(encoded_imgs2[np.array(y2_test) == 2][:, 0], encoded_imgs2[np.array(y2_test) == 2][:, 1], label='Patch', alpha=0.5)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "proj = pca.fit_transform(encoded_imgs_train) \n",
    "#proj2 = pca.transform(encoded_imgs2)\n",
    "#proj3 = pca.transform(encoded_imgs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = y_train.reshape(y_train.shape[0], -1).max(axis=1)\n",
    "label_test = y_test.reshape(y_test.shape[0], -1).max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"PCA\")\n",
    "\n",
    "plt.scatter(proj[np.array(label_train) == 1][:, 0], \n",
    "            proj[np.array(label_train) == 1][:, 1], \n",
    "            label='Calcific', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.scatter(proj[np.array(label_train) == 2][:, 0], \n",
    "            proj[np.array(label_train) == 2][:, 1], \n",
    "            label='Fibrous', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.scatter(proj[np.array(label_train) == 0][:, 0], \n",
    "            proj[np.array(label_train) == 0][:, 1], \n",
    "            label='No Plaque', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"PCA\")\n",
    "\n",
    "plt.scatter(proj[np.array(label_train) == 1][:, 0], \n",
    "            proj[np.array(label_train) == 1][:, 1], \n",
    "            label='Calcific', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.scatter(proj[np.array(label_train) == 2][:, 0], \n",
    "            proj[np.array(label_train) == 2][:, 1], \n",
    "            label='Fibrous', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.scatter(proj[np.array(label_train) == 0][:, 0], \n",
    "            proj[np.array(label_train) == 0][:, 1], \n",
    "            label='No Plaque', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"PCA\")\n",
    "plt.scatter(proj[np.array(y_test) == 0][:, 0], proj[np.array(y_test) == 0][:, 1], label='Calcific', alpha=0.5)\n",
    "plt.scatter(proj[np.array(y_test) == 1][:, 0], proj[np.array(y_test) == 1][:, 1], label='Fibrous', alpha=0.5)\n",
    "plt.scatter(proj[np.array(y_test) == 2][:, 0], proj[np.array(y_test) == 2][:, 1], label='No Plaque', alpha=0.5)\n",
    "\n",
    "#plt.scatter(proj2[np.array(y2_test) == 0][:, 0], proj2[np.array(y2_test) == 0][:, 1], label='Patch Cal', alpha=0.5)\n",
    "plt.scatter(proj2[np.array(y2_test) == 1][:, 0], proj2[np.array(y2_test) == 1][:, 1], label='Patch Fib', alpha=0.5)\n",
    "#plt.scatter(proj2[np.array(y2_test) == 2][:, 0], proj2[np.array(y2_test) == 2][:, 1], label='Patch NoPl', alpha=0.5)\n",
    "\n",
    "\n",
    "plt.scatter(proj3[np.array(y3_test) == 0][:, 0], proj3[np.array(y3_test) == 0][:, 1], label='New Cal', alpha=0.5)\n",
    "plt.scatter(proj3[np.array(y3_test) == 1][:, 0], proj3[np.array(y3_test) == 1][:, 1], label='New Fib', alpha=0.5)\n",
    "plt.scatter(proj3[np.array(y3_test) == 2][:, 0], proj3[np.array(y3_test) == 2][:, 1], label='New NoPl', alpha=0.5)\n",
    "\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(proj3[np.array(y3_test) == 0][:, 0], proj3[np.array(y3_test) == 0][:, 1], label='New Cal', alpha=0.5)\n",
    "plt.scatter(proj3[np.array(y3_test) == 1][:, 0], proj3[np.array(y3_test) == 1][:, 1], label='New Fib', alpha=0.5)\n",
    "plt.scatter(proj3[np.array(y3_test) == 2][:, 0], proj3[np.array(y3_test) == 2][:, 1], label='New NoPl', alpha=0.5)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "umap = UMAP(random_state=42)\n",
    "standard_embedding = umap.fit_transform(encoded_imgs)\n",
    "\n",
    "standard_embedding2 = umap.transform(encoded_imgs2)\n",
    "\"\"\"\n",
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], c=y_test, cmap='Spectral', alpha=0.5)\n",
    "plt.colorbar();\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "umap = UMAP(random_state=42)\n",
    "proj = umap.fit_transform(encoded_imgs_train)\n",
    "\n",
    "\"\"\"\n",
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], c=y_test, cmap='Spectral', alpha=0.5)\n",
    "plt.colorbar();\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"UMAP\")\n",
    "\n",
    "plt.scatter(proj[np.array(label_train) == 1][:, 0], \n",
    "            proj[np.array(label_train) == 1][:, 1], \n",
    "            label='Calcific', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.scatter(proj[np.array(label_train) == 2][:, 0], \n",
    "            proj[np.array(label_train) == 2][:, 1], \n",
    "            label='Fibrous', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.scatter(proj[np.array(label_train) == 0][:, 0], \n",
    "            proj[np.array(label_train) == 0][:, 1], \n",
    "            label='No Plaque', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"UMAP\")\n",
    "\n",
    "plt.scatter(proj[np.array(label_train) == 1][:, 0], \n",
    "            proj[np.array(label_train) == 1][:, 1], \n",
    "            label='Calcific', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(proj[np.array(label_train) == 2][:, 0], \n",
    "            proj[np.array(label_train) == 2][:, 1], \n",
    "            label='Fibrous', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(proj[np.array(label_train) == 0][:, 0], \n",
    "            proj[np.array(label_train) == 0][:, 1], \n",
    "            label='No Plaque', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_mask = y_train.astype(np.bool)\n",
    "\n",
    "y_train_mask_sum = y_train_mask.reshape(y_train_mask.shape[0], -1).sum(axis=1)\n",
    "\n",
    "x_train_plaque_th = x_train[y_train_mask_sum > 500]\n",
    "y_train_plaque_th = y_train[y_train_mask_sum > 500]\n",
    "encoded_imgs_train_plaque_th = encoded_imgs_train[y_train_mask_sum > 500]\n",
    "\n",
    "\n",
    "x_train_noplaque = x_train[y_train_mask_sum == 0]\n",
    "y_train_noplaque = y_train[y_train_mask_sum == 0]\n",
    "encoded_imgs_train_noplaque = encoded_imgs_train[y_train_mask_sum == 0]\n",
    "\n",
    "\n",
    "y_train_sub = np.vstack((y_train_plaque_th, y_train_noplaque))\n",
    "x_train_sub = np.vstack((x_train_plaque_th, x_train_noplaque))\n",
    "encoded_imgs_train_sub = np.vstack((encoded_imgs_train_plaque_th, encoded_imgs_train_noplaque))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_mask = y_test.astype(np.bool)\n",
    "\n",
    "y_test_mask_sum = y_test_mask.reshape(y_test_mask.shape[0], -1).sum(axis=1)\n",
    "\n",
    "x_test_plaque_th = x_test[y_test_mask_sum > 500]\n",
    "y_test_plaque_th = y_test[y_test_mask_sum > 500]\n",
    "encoded_imgs_test_plaque_th = encoded_imgs_test[y_test_mask_sum > 500]\n",
    "\n",
    "\n",
    "x_test_noplaque = x_test[y_test_mask_sum == 0]\n",
    "y_test_noplaque = y_test[y_test_mask_sum == 0]\n",
    "encoded_imgs_test_noplaque = encoded_imgs_test[y_test_mask_sum == 0]\n",
    "\n",
    "\n",
    "y_test_sub = np.vstack((y_test_plaque_th, y_test_noplaque))\n",
    "x_test_sub = np.vstack((x_test_plaque_th, x_test_noplaque))\n",
    "encoded_imgs_test_sub = np.vstack((encoded_imgs_test_plaque_th, encoded_imgs_test_noplaque))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "umap = UMAP(random_state=42)\n",
    "proj = umap.fit_transform(encoded_imgs_train_sub)\n",
    "\n",
    "\"\"\"\n",
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], c=y_test, cmap='Spectral', alpha=0.5)\n",
    "plt.colorbar();\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = y_train_sub.reshape(y_train_sub.shape[0], -1).max(axis=1)\n",
    "label_test = y_test_sub.reshape(y_test_sub.shape[0], -1).max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "plt.title(\"UMAP\")\n",
    "plt.scatter(proj[np.array(label_train) == 1][:, 0], \n",
    "            proj[np.array(label_train) == 1][:, 1], \n",
    "            label='Calcific', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.scatter(proj[np.array(label_train) == 2][:, 0], \n",
    "            proj[np.array(label_train) == 2][:, 1], \n",
    "            label='Fibrous', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.scatter(proj[np.array(label_train) == 0][:, 0], \n",
    "            proj[np.array(label_train) == 0][:, 1], \n",
    "            label='No Plaque', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "umap = UMAP(random_state=42)\n",
    "proj = umap.fit_transform(encoded_imgs_test_sub)\n",
    "\n",
    "\"\"\"\n",
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], c=y_test, cmap='Spectral', alpha=0.5)\n",
    "plt.colorbar();\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"UMAP\")\n",
    "\n",
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "plt.scatter(proj[np.array(label_test) == 1][:, 0], \n",
    "            proj[np.array(label_test) == 1][:, 1], \n",
    "            label='Calcific', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.scatter(proj[np.array(label_test) == 2][:, 0], \n",
    "            proj[np.array(label_test) == 2][:, 1], \n",
    "            label='Fibrous', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.scatter(proj[np.array(label_test) == 0][:, 0], \n",
    "            proj[np.array(label_test) == 0][:, 1], \n",
    "            label='No Plaque', \n",
    "            alpha=0.5)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"UMAP\")\n",
    "plt.scatter(standard_embedding[np.array(y_test) == 0][:, 0], standard_embedding[np.array(y_test) == 0][:, 1], alpha=0.5, label='Calcific')\n",
    "plt.scatter(standard_embedding[np.array(y_test) == 1][:, 0], standard_embedding[np.array(y_test) == 1][:, 1], alpha=0.5, label='Fibrous')\n",
    "plt.scatter(standard_embedding[np.array(y_test) == 2][:, 0], standard_embedding[np.array(y_test) == 2][:, 1], alpha=0.5, label='NoPlaque')\n",
    "\n",
    "plt.scatter(standard_embedding2[np.array(y2_test) == 0][:, 0], standard_embedding2[np.array(y2_test) == 0][:, 1], label='Patch Cal', alpha=0.5)\n",
    "plt.scatter(standard_embedding2[np.array(y2_test) == 1][:, 0], standard_embedding2[np.array(y2_test) == 1][:, 1], label='Patch Fib', alpha=0.5)\n",
    "#plt.scatter(standard_embedding2[np.array(y2_test) == 2][:, 0], standard_embedding2[np.array(y2_test) == 2][:, 1], label='Patch NoPl', alpha=0.5)\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(standard_embedding2[np.array(y2_test) == 0][:, 0], standard_embedding2[np.array(y2_test) == 0][:, 1], label='Patch Cal', alpha=0.5)\n",
    "plt.figure()\n",
    "plt.scatter(standard_embedding2[np.array(y2_test) == 1][:, 0], standard_embedding2[np.array(y2_test) == 1][:, 1], label='Patch NoPl', alpha=0.5)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(standard_embedding2[np.array(y2_test) == 2][:, 0], standard_embedding2[np.array(y2_test) == 2][:, 1], label='Patch Fib', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "emb = tsne.fit_transform(encoded_imgs)\n",
    "\n",
    "emb2 = tsne.transform(encoded_imgs2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"T-SNE\")\n",
    "plt.scatter(emb[np.array(y_test) == 0][:, 0], tsne[np.array(y_test) == 0][:, 1], alpha=0.5, label='Calcific')\n",
    "plt.scatter(emb[np.array(y_test) == 1][:, 0], tsne[np.array(y_test) == 1][:, 1], alpha=0.5, label='Fibrous')\n",
    "plt.scatter(emb[np.array(y_test) == 2][:, 0], tsne[np.array(y_test) == 2][:, 1], alpha=0.5, label='NoPlaque')\n",
    "\n",
    "plt.scatter(emb2[np.array(y2_test) == 0][:, 0], emb2[np.array(y2_test) == 0][:, 1], label='Patch', alpha=0.5)\n",
    "plt.scatter(emb2[np.array(y2_test) == 1][:, 0], emb2[np.array(y2_test) == 1][:, 1], label='Patch', alpha=0.5)\n",
    "plt.scatter(emb2[np.array(y2_test) == 2][:, 0], emb2[np.array(y2_test) == 2][:, 1], label='Patch', alpha=0.5)\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "\n",
    "mds = MDS(n_components=2).fit_transform(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"MDS\")\n",
    "plt.scatter(mds[np.array(y_test) == 0][:, 0], mds[np.array(y_test) == 0][:, 1], alpha=0.5, label='Calcific')\n",
    "plt.scatter(mds[np.array(y_test) == 1][:, 0], mds[np.array(y_test) == 1][:, 1], alpha=0.5, label='Fibrous')\n",
    "plt.scatter(mds[np.array(y_test) == 2][:, 0], mds[np.array(y_test) == 2][:, 1], alpha=0.5, label='NoPlaque')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
