{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## load the libraries \n",
    "%matplotlib inline\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "import glob\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import *\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model, Sequential\n",
    "from keras.metrics import *\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from scipy.stats import norm\n",
    "from keras.preprocessing import image\n",
    "from keras import datasets\n",
    "\n",
    "from keras import backend as K\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import exposure\n",
    "plt.gray()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" #model will be trained on GPU 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    x_size = 64\n",
    "    y_size = 64\n",
    "    image_list = np.zeros((len(path), x_size, y_size,1))\n",
    "    for i, fig in enumerate(path):\n",
    "        img = image.load_img(fig, color_mode='grayscale', target_size=(x_size, y_size))\n",
    "        img = image.img_to_array(img).astype('float32')\n",
    "        img = img / 255.0\n",
    "        '''\n",
    "        max_i = img.max()\n",
    "        min_i = img.min()\n",
    "\n",
    "        img = (img - min_i) / (max_i - min_i)\n",
    "        '''\n",
    "        \n",
    "        image_list[i] = img#exposure.equalize_adapthist(img[:,:,0])\n",
    "        \n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "train_img = glob.glob(\"/home/webvalley/Documents/plaque-image-preprocessing/Data/Patches/Plaque/Aug/cal/*.png\")\n",
    "train_img += glob.glob(\"/home/webvalley/Documents/plaque-image-preprocessing/Data/Patches/Plaque/Aug/fibrous/*.png\")\n",
    "train_img += random.sample(glob.glob(\"/home/webvalley/Documents/plaque-image-preprocessing/Data/Patches/NoPlaque/*.png\"), 3790)\n",
    "\"\"\"\n",
    "train_img = glob.glob(\"train/*.png\")\n",
    "\n",
    "test_img = glob.glob(\"test/*.png\")\n",
    "\n",
    "\n",
    "random.shuffle(train_img)\n",
    "random.shuffle(test_img)\n",
    "\n",
    "x_train = load_image(train_img)\n",
    "x_test = load_image(test_img) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-936e6cffc83d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_i\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_i\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexposure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequalize_adapthist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/plaque-img/lib/python3.7/site-packages/skimage/color/adapt_rgb.py\u001b[0m in \u001b[0;36mimage_filter_adapted\u001b[0;34m(image, *args, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mapply_to_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimage_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimage_filter_adapted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/plaque-img/lib/python3.7/site-packages/skimage/exposure/_adapthist.py\u001b[0m in \u001b[0;36mequalize_adapthist\u001b[0;34m(image, kernel_size, clip_limit, nbins)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_clahe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_limit\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnbins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_as_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrescale_intensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/plaque-img/lib/python3.7/site-packages/skimage/exposure/_adapthist.py\u001b[0m in \u001b[0;36m_clahe\u001b[0;34m(image, kernel_size, clip_limit, nbins)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             interpolate(image, cslice, rslice,\n\u001b[0;32m--> 192\u001b[0;31m                         mapLU, mapRU, mapLB, mapRB, lut)\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0mcstart\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mc_offset\u001b[0m  \u001b[0;31m# set pointer on next matrix */\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/plaque-img/lib/python3.7/site-packages/skimage/exposure/_adapthist.py\u001b[0m in \u001b[0;36minterpolate\u001b[0;34m(image, xslice, yslice, mapLU, mapRU, mapLB, mapRB, lut)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;31m# interpolation weight matrices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     x_coef, y_coef = np.meshgrid(np.arange(xslice.size),\n\u001b[0;32m--> 320\u001b[0;31m                                  np.arange(yslice.size))\n\u001b[0m\u001b[1;32m    321\u001b[0m     \u001b[0mx_inv_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_inv_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_coef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_coef\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/plaque-img/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmeshgrid\u001b[0;34m(*xi, **kwargs)\u001b[0m\n\u001b[1;32m   4197\u001b[0m     \u001b[0ms0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4198\u001b[0m     output = [np.asanyarray(x).reshape(s0[:i] + (-1,) + s0[i + 1:])\n\u001b[0;32m-> 4199\u001b[0;31m               for i, x in enumerate(xi)]\n\u001b[0m\u001b[1;32m   4200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4201\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindexing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'xy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/plaque-img/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   4196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4197\u001b[0m     \u001b[0ms0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4198\u001b[0;31m     output = [np.asanyarray(x).reshape(s0[:i] + (-1,) + s0[i + 1:])\n\u001b[0m\u001b[1;32m   4199\u001b[0m               for i, x in enumerate(xi)]\n\u001b[1;32m   4200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, img in enumerate(x_train):\n",
    "    max_i = img.max()\n",
    "    min_i = img.min()\n",
    "    if max_i == min_i:\n",
    "        img = np.zeros((64,64,1))\n",
    "    else:\n",
    "        img = (img - min_i) / (max_i - min_i)\n",
    "        img = exposure.equalize_adapthist(img[:,:,0])\n",
    "    \n",
    "    x_train[i] = img.reshape(64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_train[0].reshape(64,64))\n",
    "plt.show()\n",
    "plt.imshow(img.reshape(64,64))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "imgs = glob.glob(\"/home/webvalley/Documents/plaque-image-preprocessing/AutoEncoder/test/*.png\")\n",
    "print(imgs[len(imgs)-1])\n",
    "\n",
    "\n",
    "for _ in range(200):\n",
    "    r = random.randint(0, len(imgs)-1)\n",
    "    name = imgs[r].split(\"/\")[-1]\n",
    "    while not \"noplaque\" in name:\n",
    "        r = random.randint(0, len(imgs))\n",
    "        name = imgs[r].split(\"/\")[-1]\n",
    "    \n",
    "    print('mv \"' + imgs[r] + '\" /home/webvalley/Documents/plaque-image-preprocessing/AutoEncoder/train')\n",
    "\n",
    "    os.system('mv \"' + imgs[r] + '\" /home/webvalley/Documents/plaque-image-preprocessing/AutoEncoder/train')\n",
    "\n",
    "\n",
    "for im in glob.glob(\"/home/webvalley/Documents/plaque-image-preprocessing/Data/Patches/Plaque/Aug/cal/*.png\"):\n",
    "    #print(im)\n",
    "    os.system(f\"cp {im} train\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = []\n",
    "\n",
    "for img in test_img:\n",
    "    if \"Calcific\" in img:\n",
    "        y_test.append(0)\n",
    "    elif \"Fibrous\" in img:\n",
    "        y_test.append(1)\n",
    "    elif \"noplaque\" in img:\n",
    "        y_test.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 20\n",
    "inChannel = 1\n",
    "x, y = 64, 64\n",
    "input_img = Input(shape = (x, y, inChannel))\n",
    "print(input_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols, img_chns = x, y, 1\n",
    "# number of convolutional filters to use\n",
    "NB_FILTERS = 16\n",
    "# convolution kernel size\n",
    "KERNEL_SIZE = (3, 3)\n",
    "\n",
    "\n",
    "LATENT_DIM = 128\n",
    "INTERMEDIATE_DIM = 256\n",
    "NB_EPOCHS = 100\n",
    "\n",
    "conv_1 = Conv2D(1, kernel_size=(2, 2), padding='same', activation='relu')(input_img)\n",
    "conv_2 = Conv2D(NB_FILTERS, kernel_size=(2, 2),\n",
    "                       padding='same', activation='relu',\n",
    "                       strides=(2, 2))(conv_1)\n",
    "conv_3 = Conv2D(NB_FILTERS, KERNEL_SIZE,\n",
    "                       padding='same', activation='relu',\n",
    "                       strides=(1, 1))(conv_2)\n",
    "conv_4 = Conv2D(NB_FILTERS, KERNEL_SIZE,\n",
    "                       padding='same', activation='relu',\n",
    "                       strides=(1, 1))(conv_3)\n",
    "flat = Reshape((-1,))(conv_4)\n",
    "hidden = Dense(INTERMEDIATE_DIM, activation='relu')(flat)\n",
    "\n",
    "z = Dense(LATENT_DIM)(hidden)\n",
    "\n",
    "decoder_hid = Dense(INTERMEDIATE_DIM, activation='relu')(z)\n",
    "decoder_upsample = Dense(NB_FILTERS * img_rows//2 * img_rows//2, activation='relu')(decoder_hid)\n",
    "\n",
    "decoder_reshape = Reshape((img_rows//2, img_rows//2, NB_FILTERS))(decoder_upsample)\n",
    "decoder_deconv_1 = Conv2DTranspose(NB_FILTERS, KERNEL_SIZE,\n",
    "                                   padding='same',\n",
    "                                   strides=(1, 1),\n",
    "                                   activation='relu')(decoder_reshape)\n",
    "decoder_deconv_2 = Conv2DTranspose(NB_FILTERS, KERNEL_SIZE,\n",
    "                                   padding='same',\n",
    "                                   strides=(1, 1),\n",
    "                                   activation='relu')(decoder_deconv_1)\n",
    "\n",
    "decoder_deconv_3_upsamp = Conv2DTranspose(NB_FILTERS, kernel_size=(2, 2),\n",
    "                                          padding='valid',\n",
    "                                          strides=(2, 2),\n",
    "                                          activation='relu')(decoder_deconv_2)\n",
    "decoder_mean_squash = Conv2D(img_chns, kernel_size=(1, 1),\n",
    "                                    padding='valid',\n",
    "                                    activation='sigmoid')(decoder_deconv_3_upsamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"FUNZIONANTE\n",
    "# Encoder\n",
    "encoded = Conv2D(2,(3,3),\n",
    "           activation='relu',\n",
    "           padding='same')(input_img)\n",
    "encoded = Conv2D(2,(3,3),\n",
    "           activation='relu',\n",
    "           padding='same')(encoded)\n",
    "encoded = MaxPooling2D((2,2))(encoded) \n",
    "encoded = Conv2D(4,(3,3),\n",
    "           activation='relu',\n",
    "           padding='same')(encoded)\n",
    "encoded = Conv2D(4,(3,3),\n",
    "           activation='relu',\n",
    "           padding='same')(encoded)\n",
    "encoded = MaxPooling2D((2,2))(encoded) \n",
    "encoded = Flatten()(encoded)\n",
    "encoded = Dense(64, activation='relu')(encoded)\n",
    "encoded = Dense(4)(encoded)\n",
    "\n",
    "# Decoder\n",
    "decoded = Dense(64, activation='relu')(encoded)\n",
    "decoded = Dense(1024, activation='relu')(decoded)\n",
    "decoded = Reshape((7,7,4))(decoded)\n",
    "decoded = UpSampling2D((2, 2))(decoded)\n",
    "decoded = Conv2D(4, (3, 3),\n",
    "           activation='relu',\n",
    "           padding='same')(decoded)\n",
    "decoded = Conv2D(2, (3, 3),\n",
    "           activation='relu',\n",
    "           padding='same')(decoded)\n",
    "decoded = UpSampling2D((2, 2))(decoded) \n",
    "decoded = Conv2D(2, (3, 3),\n",
    "           activation='relu',\n",
    "           padding='same')(decoded)\n",
    "decoded = Conv2D(1, (3, 3),\n",
    "           padding='same')(decoded)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# encoding architecture\n",
    "encoded = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n",
    "print(encoded.shape)\n",
    "encoded = MaxPool2D( (2, 2), padding='same')(encoded)\n",
    "encoded = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "encoded = MaxPool2D( (2, 2), padding='same')(encoded)\n",
    "encoded = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "encoded = MaxPool2D((2, 2), padding='same')(encoded)\n",
    "encoded = Flatten()(encoded)\n",
    "encoded = Dense(128)(encoded)\n",
    "encoded = Dense(2)(encoded)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# decoding architecture\n",
    "decoded = Dense(256)(encoded)\n",
    "decoded = Reshape((4, 4, 16))(decoded)\n",
    "decoded = UpSampling2D((2, 2))(decoded)\n",
    "decoded = Conv2D(16, (3, 3), activation='relu', padding='same')(decoded)\n",
    "decoded = UpSampling2D((2, 2))(decoded)\n",
    "decoded = Conv2D(32, (3, 3), activation='relu', padding='same')(decoded)\n",
    "decoded = UpSampling2D((2, 2))(decoded)\n",
    "decoded = Conv2D(64, (3, 3), activation='relu', padding='same')(decoded)\n",
    "decoded = UpSampling2D((2, 2))(decoded)\n",
    "decoded = Conv2D(1, (3, 3), padding='same')(decoded)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "smooth = 1\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1-dice_coef(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "\n",
    "model = Model(input_img, decoder_mean_squash)\n",
    "model.compile(optimizer=Adam(lr=0.0001), loss='mse')#dice_coef, metrics=[dice_coef_loss])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=5, mode='auto')\n",
    "history = model.fit(x_train, x_train, epochs=100, batch_size=batch_size, validation_data=(x_test, x_test))#, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model.save('autoencoder_model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "\n",
    "# adam = optimizers.Adam(lr=0.01)\n",
    "\n",
    "encoder = Model(input_img, z)\n",
    "encoder.compile(optimizer=Adam(lr=0.0001), loss='mse')#dice_coef, metrics=[dice_coef_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs.shape\n",
    "#print(encoded_imgs[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_conv = {\n",
    "    0: 'Calcific',\n",
    "    1: 'Fibrous',\n",
    "    2: 'NoPlaque'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(11):\n",
    "    fig, ((ax1, ax2, ax3)) = plt.subplots(1, 3)\n",
    "    \n",
    "    fig.suptitle(f\"[{i}] Label: \" + label_conv[y_test[i]], fontsize=16)\n",
    "    \n",
    "    ax1.imshow(x_test[i].reshape((64, 64)))\n",
    "    ax1.set_title(\"Original\")\n",
    "    \n",
    "    ax1.get_xaxis().set_visible(False)\n",
    "    ax1.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax2.imshow(encoded_imgs[i].reshape((16, 8)))\n",
    "    ax2.set_title(\"Encoded\")\n",
    "    \n",
    "    ax2.get_xaxis().set_visible(False)\n",
    "    ax2.get_yaxis().set_visible(False)\n",
    "    \n",
    "    ax3.imshow(decoded_imgs[i].reshape((64, 64)))\n",
    "    ax3.set_title(\"Decoded\")\n",
    "    \n",
    "    ax3.get_xaxis().set_visible(False)\n",
    "    ax3.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cos_sim = cosine_similarity(encoded_imgs[2].reshape(1,-1), encoded_imgs[1].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.subtract(encoded_imgs[0], encoded_imgs[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoded_imgs[np.array(y_test) == 1]\n",
    "plt.title(\"SCATTER\")\n",
    "plt.scatter(encoded_imgs[np.array(y_test) == 0][:, 0], encoded_imgs[np.array(y_test) == 0][:, 1], label='Calcific', alpha=0.5)\n",
    "plt.scatter(encoded_imgs[np.array(y_test) == 1][:, 0], encoded_imgs[np.array(y_test) == 1][:, 1], label='Fibrous', alpha=0.5)\n",
    "plt.scatter(encoded_imgs[np.array(y_test) == 2][:, 0], encoded_imgs[np.array(y_test) == 2][:, 1], label='No Plaque', alpha=0.5)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "proj = pca.fit_transform(encoded_imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"PCA\")\n",
    "plt.scatter(proj[np.array(y_test) == 0][:, 0], proj[np.array(y_test) == 0][:, 1], label='Calcific', alpha=0.5)\n",
    "plt.scatter(proj[np.array(y_test) == 1][:, 0], proj[np.array(y_test) == 1][:, 1], label='Fibrous', alpha=0.5)\n",
    "plt.scatter(proj[np.array(y_test) == 2][:, 0], proj[np.array(y_test) == 2][:, 1], label='No Plaque', alpha=0.5)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "\n",
    "\n",
    "standard_embedding = umap.UMAP(random_state=42).fit_transform(encoded_imgs)\n",
    "\"\"\"\n",
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], c=y_test, cmap='Spectral', alpha=0.5)\n",
    "plt.colorbar();\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"UMAP\")\n",
    "plt.scatter(standard_embedding[np.array(y_test) == 0][:, 0], standard_embedding[np.array(y_test) == 0][:, 1], alpha=0.5)\n",
    "plt.scatter(standard_embedding[np.array(y_test) == 1][:, 0], standard_embedding[np.array(y_test) == 1][:, 1], alpha=0.5)\n",
    "plt.scatter(standard_embedding[np.array(y_test) == 2][:, 0], standard_embedding[np.array(y_test) == 2][:, 1], alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=3,perplexity=40).fit_transform(encoded_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"T-SNE\")\n",
    "plt.scatter(tsne[np.array(y_test) == 0][:, 0], tsne[np.array(y_test) == 0][:, 1], alpha=0.5)\n",
    "plt.scatter(tsne[np.array(y_test) == 1][:, 0], tsne[np.array(y_test) == 1][:, 1], alpha=0.5)\n",
    "plt.scatter(tsne[np.array(y_test) == 2][:, 0], tsne[np.array(y_test) == 2][:, 1], alpha=0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
