{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "import skimage\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_val_score, RepeatedKFold\n",
    "from sklearn.metrics import matthews_corrcoef as mcc\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pydicom\n",
    "import random\n",
    "\n",
    "output_txt = open(\"output.txt\",\"w\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matthews_correlation(y_true, y_pred):\n",
    "    '''Calculates the Matthews correlation coefficient measure for quality\n",
    "    of binary classification problems.\n",
    "    \n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())\n",
    "    '''\n",
    "    return mcc(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mcc(yval, yval_rk):\n",
    "    ycat = np.zeros(yval_rk.shape[0])\n",
    "    x = 0\n",
    "    for val in yval_rk:\n",
    "        index = np.argmax(val)\n",
    "        ycat[x] = index\n",
    "        x += 1\n",
    "    yreal = np.zeros(ycat.shape)\n",
    "    for i in range(yval.shape[0]):\n",
    "        yreal[i] = np.argmax(yval[i])\n",
    "    #print(yreal)\n",
    "    #print(ycat)\n",
    "    #print('MCC: ', str(mcc(yreal, ycat)))\n",
    "    return mcc(yreal,ycat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(ytr, Xtr):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Conv2D(64, (5, 5), input_shape = (64, 64, 1), activation = 'relu'))\n",
    "    classifier.add(Dropout(0.4))\n",
    "    classifier.add(MaxPooling2D(pool_size = (4, 4)))\n",
    "    classifier.add(Conv2D(32, (4, 4), activation = 'relu'))\n",
    "    classifier.add(Dropout(0.2))\n",
    "    classifier.add(MaxPooling2D(pool_size = (4, 4)))\n",
    "    classifier.add(Flatten())\n",
    "    classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "    classifier.add(Dropout(0.3))\n",
    "    classifier.add(Dense(units = 32, activation = 'relu'))\n",
    "    classifier.add(Dense(units = 3, activation = 'softmax'))\n",
    "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(x, B=1000, alpha=0.05, seed=0):\n",
    "    \"\"\"Computes the (1-alpha) Bootstrap confidence interval\n",
    "    from empirical bootstrap distribution of sample mean.\n",
    "\n",
    "    The lower and upper confidence bounds are the (B*alpha/2)-th\n",
    "    and B * (1-alpha/2)-th ordered means, respectively.\n",
    "    For B = 1000 and alpha = 0.05 these are the 25th and 975th\n",
    "    ordered means.\n",
    "    \"\"\"\n",
    "\n",
    "    x_arr = np.ravel(x)\n",
    "\n",
    "    if B < 2:\n",
    "        raise ValueError(\"B must be >= 2\")\n",
    "\n",
    "    if alpha < 0 or alpha > 1:\n",
    "        raise ValueError(\"alpha must be in [0, 1]\")\n",
    "\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    bmean = np.empty(B, dtype=np.float)\n",
    "    for b in range(B):\n",
    "        idx = np.random.random_integers(0, x_arr.shape[0]-1, x_arr.shape[0])\n",
    "        bmean[b] = np.mean(x_arr[idx])\n",
    "\n",
    "    bmean.sort()\n",
    "    lower = int(B * (alpha * 0.5))\n",
    "    upper = int(B * (1 - (alpha * 0.5)))\n",
    "\n",
    "    return (bmean[lower], bmean[upper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats(mcc1, mcc2):\n",
    "    total = 0\n",
    "    inrange = 0\n",
    "    outofrange = 0\n",
    "    for num in mcc1:\n",
    "        total += num\n",
    "    avg = total/len(mcc1)\n",
    "    min1 = np.amin(mcc1)\n",
    "    max1 = np.amax(mcc1)\n",
    "    conf_int = bootstrap_ci(mcc1)\n",
    "    lower = conf_int[0]\n",
    "    upper = conf_int[1]\n",
    "    for num in mcc2:\n",
    "        if(mcc2<upper and mcc2>lower):\n",
    "            print('MCC is in confidence interval')\n",
    "            inrange += 1\n",
    "        else:\n",
    "            print('MCC is NOT in confidence interval')\n",
    "            outofrange += 1\n",
    "    return avg, min1, max1, conf_int, inrange, outofrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Xtemp = []\n",
    "ytemp = []\n",
    "X = []\n",
    "y = []\n",
    "index = []\n",
    "\n",
    "count0 = 0\n",
    "dir = \"./Data/Patches/NoPlaque\"\n",
    "for filename in os.listdir(dir):\n",
    "    img = np.array(cv2.imread(os.path.join(dir, filename)))[:,:,0:1]\n",
    "    #img = np.load(os.path.join(dir, filename))[:,:,0]\n",
    "    Xtemp.append(img)\n",
    "    ytemp.append([1,0,0])\n",
    "while(len(index) != 4000):\n",
    "    r = random.randint(1,4000)\n",
    "    if r not in index: \n",
    "        index.append(r)\n",
    "for i in index:\n",
    "    X.append(Xtemp[i])\n",
    "    y.append(ytemp[i])\n",
    "count0 = len(X)\n",
    "\n",
    "count1 = 0\n",
    "dir = \"./Data/Patches/Plaque/Aug/cal\"\n",
    "for filename in os.listdir(dir):\n",
    "    img = np.array(cv2.imread(os.path.join(dir, filename)))[:,:,0:1]\n",
    "    #img = np.load(os.path.join(dir, filename))[:,:,0]\n",
    "    X.append(img)\n",
    "    y.append([0,1,0])\n",
    "    count1 += 1\n",
    "\n",
    "count2 = 0\n",
    "dir = \"./Data/Patches/Plaque/Aug/fibrous\"\n",
    "for filename in os.listdir(dir):\n",
    "    img = np.array(cv2.imread(os.path.join(dir, filename)))[:,:,0:1]\n",
    "    #img = np.load(os.path.join(dir, filename))[:,:,0]\n",
    "    X.append(img)\n",
    "    y.append([0,0,1])  \n",
    "    count2 += 1\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "#print(X.shape)\n",
    "#print(X[0].shape)\n",
    "#seeds = range(2, 60, 10)\n",
    "#for i, seed in enumerate(seeds):\n",
    "#k_fold = KFold(len(y), n_folds=10, shuffle=True, random_state=0)\n",
    "#rskf = RepeatedStratifiedKFold(n_splits=5, n_repeats=5)\n",
    "#clf = get_model(ytr,Xtr)\n",
    "#print(cross_val_score(clf, X, y, cv=rskf, n_jobs=1, scoring = 'accuracy'))\n",
    "#clf.summary()\n",
    "#history = classifier.fit(Xtr, ytr,\n",
    "                #callbacks = [es],\n",
    "                #epochs = 40,\n",
    "                #batch_size = 32,\n",
    "                #validation_data = (Xts, yts),\n",
    "                #class_weight = class_weight)\n",
    "#y_tr_r = classifier.predict(y_tr)\n",
    "#print('MCC: ', str(mcc(y_tr, y_tr_r)))\n",
    "#clf.evaluate(Xts, yts)\n",
    "#clf.save(\"./Models/model/KFold\" + str(train_index) + \".h5\")\n",
    "#json.dump(history.history, open(\"./Models/JSON/KFold\" + str(train_index) + \".json\", \"w\"))\n",
    "\n",
    "weight_for_0 = 1. / count0\n",
    "weight_for_1 = 1. / count1\n",
    "weight_for_2 = 1. / count2\n",
    "Xtr, Xts, ytr, yts = train_test_split(np.copy(X), np.copy(y), test_size=0.25)#, random_state=seed)\n",
    "#ytr_categorical = keras.utils.to_categorical(ytr, num_classes = 3)\n",
    "rskf = RepeatedKFold(n_splits=5, n_repeats=4)\n",
    "mcc_all = []\n",
    "mcc_tr = []\n",
    "n = 0\n",
    "\n",
    "for train_index, val_index in rskf.split(Xtr, ytr):\n",
    "    #print(\"TRAIN:\", train_index, \"VAL:\", val_index)\n",
    "    Xtrk, Xval = Xtr[train_index], Xtr[val_index]\n",
    "    ytrk, yval = ytr[train_index], ytr[val_index]\n",
    "\n",
    "    mean = np.mean(Xtrk, axis=0)\n",
    "    Xtrk = np.subtract(Xtrk,mean)\n",
    "    Xtsk = np.subtract(Xval,mean)\n",
    "    std = np.std(Xtrk, axis=0)\n",
    "    Xtrk = np.divide(Xtrk,std)\n",
    "    Xtsk = np.divide(Xval,std)\n",
    "    classifier = get_model(ytrk, Xtrk)\n",
    "    classifier.summary()\n",
    "\n",
    "    print(\"Run: \", n)\n",
    "    es = EarlyStopping(patience=5, restore_best_weights = True)\n",
    "    class_weights = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2}\n",
    "    \n",
    "    history = classifier.fit(Xtrk, ytrk,\n",
    "                    callbacks = [es],\n",
    "                    epochs = 40,\n",
    "                    batch_size = 32,\n",
    "                    validation_data = (Xval, yval),\n",
    "                    class_weight = class_weights)\n",
    "\n",
    "    yval_rk = classifier.predict(Xval)\n",
    "    mcc_tr.append(calc_mcc(yval, yval_rk))\n",
    "    print('MCC ', str(n), ': ', str(calc_mcc(yval, yval_rk)))\n",
    "    output_txt.write('MCC ', str(n), ': ', str(calc_mcc(yval, yval_rk)))\n",
    "    classifier.evaluate(Xval, yval)\n",
    "    classifier.save(\"./Models/model/KFold_\" + str(n) + \".h5\")\n",
    "    json.dump(history.history, open(\"./Models/JSON/KFold_\" + str(n) + \".json\", \"w\"))\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain network without kfold validation\n",
    "mean = np.mean(Xtr, axis=0)\n",
    "Xtr = np.subtract(Xtr,mean)\n",
    "Xts = np.subtract(Xts,mean)\n",
    "std = np.std(Xtr, axis=0)\n",
    "Xtr = np.divide(Xtr,std)\n",
    "Xts = np.divide(Xts,std)\n",
    "classifier = get_model(ytr, Xtr)\n",
    "classifier.summary()\n",
    "history = classifier.fit(Xtr, ytr,\n",
    "                callbacks = [es],\n",
    "                epochs = 40,\n",
    "                batch_size = 32,\n",
    "                validation_data = (Xts, yts),\n",
    "                class_weight = class_weights)\n",
    "yval_r = classifier.predict(Xts)\n",
    "mcc_all.append(calc_mcc(yval, yval_r))\n",
    "print('MCC: ', str(calc_mcc(yval, yval_r)))\n",
    "classifier.evaluate(Xts, yts)\n",
    "classifier.save(\"./Models/model/noKFold_final.h5\")\n",
    "json.dump(history.history, open(\"./Models/JSON/noKFold_final.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg, minimum, maximum, conf_int, inrange, outofrange = stats(mcc_tr, mcc_all)\n",
    "output_txt.write('Avg MCC: ', str(avg))\n",
    "output_txt.write('Min MCC: ', str(minimum))\n",
    "output_txt.write('Max MCC: ', str(maximum))\n",
    "output_txt.write('Confidence Interval: (', str(conf_int[0]), ', ', str(conf_int[1]), ')')\n",
    "output_txt.write(str(outofrange), ' MCC values outside confidence interval')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
